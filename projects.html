<head>
	<title>Projects</title>
	<link rel="stylesheet" type="text/css" href="mystyle.css">
</head>
<h2> Deep Learning Projects </h2>

<p> Neural networks are a computational tool, which can be used for machine related tasks such as data classification, image annotation and image segmentation. These consist of units known as neurons, which are inspired by biological neurons present in brain cells. When multiple neurons, each having a similar function are arranged together the resulting arrangement is known as a layer. Typically neural networks have atleast three different types of layers, an input layer used for broadcasting the input to subsequent layers, an output layer for converting the neural network response to a form most suitable for the particular task and one or more hidden layer. The hidden layers work by mapping the input data into increasingly complex manifolds or dimensions, such that characteristics of the data can be used to perform the machine task accurately.</p>

<p> Deep learning classifiers are a part of the family of neural networks, and consist of far more hidden layers than conventional neural networks. In addition, the function of each hidden layer is usually different from that of its neighboring layers. Using these different layers, deep learning classifiers can not only learn better mappings of input data, but also better combinations of these mappings. This improves the accuracy of the classifier tremendously. Hence deep learning models have been used in many state-of-the-art applications such as handwritten digit classification, self-driving cars and synthetic image synthesis, with new applications being used or updated regularly. </p>

<h3> Segmentation of eating gestures </h3>
<p>A gesture is an activity of unspecified duration from the pre-defined set of known activities. Similar to sign-language in which specific manual articulations of the hands are associated with certain words or phrases, specific movements of the wrist during a meal can be associated with a particular gesture type. The ground truth for our model was marked by 18 human raters who observed subjects eating meals using a custom tool built by our group and hence needed to be trained beforehand in order to reduce the disrepancy between themselves. A total of 51,614 gestures were identified for a data set containing recordings from 276 participants, of which data corresponding to 264 participants was retained using the following definitions: </p>
<ol type="1">
	<li><b>Bite:</b> Any movement associated with moving food towards the mouth, need not specifically include movement from a plate towards the mout. Multiple small bites may be considered as a single gesture if these do not occur more than 1 second apart from each other.</li>

	<li><b>Drink:</b> Same as that for a bite, but multiple drinks should each be separated as an individual gesture.</li>
	
	<li><b>Utensiling:</b> Motion associated with getting food/beverage ready for consumption, such as cutting food into bite sized pieces and stirring a liquid. As soon as the hand starts moving towards the mouth, the associated intake gesture (bite/drink) should be used instead.</li>

	<li><b>Rest:</b> Activity associated with periods of rest that occur in between other gestures. It ends as soon as intent to perform other activity becomes clear.</li>

	<li><b>Other:</b> All other wrist motion such as using a napkin to clean the face, moving plates away, gesturing to a friend etc. can be treated as the other category. This category included all ambiguous activity from the earlier categories.</li>

	<li><b>Unlabeled:</b> Any activity not marked by the human raters was treated as the unlabeled type. Its significance is explained later.</li>
</ol>

<p>For more information on the process of generating ground truth labels, the interested reader is asked to refer to <a href="http://cecas.clemson.edu/~ahoover/cafeteria/">Clemson Cafeteria Dataset</a>, or contact me using the email address mentioned just before <a href="index.html">About me</a>.</p>

<p>
<figure>
	<img src="images/gt-gestures-ani.gif" style="width:50%;border:1px solid black"> <!--798/476!--> 
	<figcaption> Different gestures during a meal, marked with red: bite, aqua: drink, orange: utensiling, black: rest and gray: other.</figcaption>
</figure>
</p>

<p>
<figure>
	<img src="images/cafeviewgt_no_scale.png" style="width:50%;border:1px solid black"> <!--1422/727!--> 
	<figcaption> A portion of a meal after bring marked by trained raters.</figcaption>
</figure>
</p>











