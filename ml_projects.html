<head>
	<title>Machine learning</title>
	<link rel="stylesheet" type="text/css" href="mystyle.css">
</head>

<body>
    <div class="topnav">
		<a href="index.html">Homepage</a>
		<a href="Resume_YYLuktuke_ML.pdf">Resume</a>
		<div class="dropdown">
			<button class="dropbtn">Projects
				<i class="fa fa-caret-down"></i>
			</button>
			<div class="dropdown-content">
				<a href="projects.html">Deep learning</a>
				<a href="sp_projects.html">Speech processing</a>
				<!--<a href="ml_projects.html">Machine Learning</a>-->
			</div>
		</div>
		<a href="volunteer_work.html">Extra-curricular activities</a>
		<a href="https://www.linkedin.com/in/yyl1109/">LinkedIn</a>			
    </div>

    <div class="content">
		<h2>Machine learning</h2>
		<p>Machine learning is the study of computer algorithms that learn to do a task by incrementally improving the model that is fit to data known as training data. Model fitting is the approach in which a mathematical equation or series of equations is used to describe the available data. Model fitting makes use of one or more characteristics of the data such as its appearance or distribution to generate such an equation or set of equations that describe the available data. Model fitting is used extensively in engineering and scientific studies to understand an underlying process that generates the available data.</p>
		
		<p>The usefulness of a model is determined by how accurately the equation or set of equations can be used to describe the data already available, or new data that becomes available after a model is fit to a particular data set. In machine learning fits, the model is fit to data known as training data. However the performance of a machine learning model is usually determined based on how well the model can predict or describe data that it has not seen before, which is called the test data. This is usually a part of the training data itself, but is separated before the model is fit, and reserved for testing once a suitable model has been found. This process is also known as training the machine learning algorithm.</p>
		
		<p> We may also choose to evaluate the model continuously, as it is being trained, by further separating a small part of training data before the model is fit and evaluating the model performance on both the training data and the new data set known as validation data. In such a case, we expect that the model performance improves incrementally well for both the training data and the validation data during training. This is considered separate from the model performance on the test data, which is evaluated once the model has been trained.</p>

		<p>Based on the available data, and the choice of model that is being fit to it, machine learning can be broadly classified into supervised learning and unsupervised learning. In the former, the expected behavior of the model is known beforehand and is stored in vectors known as targets or labels for the model to train on. These are usually generated synthetically by humans that can observe the original process, and hence know how to characterize its behavior. In contrast, in unsupervised learning, the target vectors are unknown or cannot be generated. The machine learning model that is fit to such data typically makes use of some or the other optimality criterion that can be easily understood based on the characteristic of the data such as its apparance, distribution or the relationship between its components.</p>

		<h3> Predicting on census data</h3>
		<p> This project was part of my course Machine Learning at TU Delft. It was created as a Kaggle competition, seen here <a href="https://www.kaggle.com/c/final-assignment-in43202">Final Assignment IN4320</a>. The goal was to study different approaches for data processing, and classification that could be used to predict if a person would earn 40,000 Euros a year based on data collected from the census bureau. This was challenging because such data typically contains missing entries, because people do not answer all optional questions in surveys, which are the common way of collecting such data. In addition, the data contained both continuous and categorical features, with no particular ordering in the categorical variables. The instructors added an additional level of difficulty by increasing the percentage of missing entries, either by manual intervention or by choosing a particularly difficult data set to begin with. However the specific mode of data acquisition was not conveyed to us.</p>

		<h4>Data</h4>
		<p> A typical example of data contained in the data set is seen below. Please note that the entries with not a number (NaN) indicate that the data for that particular column are missing for the particular data entry.</p>
		<table class="center">
			<caption> Data set containing missing entries </caption>
			<tr> <th>age</th> <th>work</th> <th>education</th> <th>education years</th> <th>marital status</th> <th>occupation</th> <th>relationship</th> <th>race</th> <th>sex</th> <th>investment income</th> <th>investment losses</th> <th>work (hrs/week)</th> <th>native country</th>	</tr>

			<tr> <td>12.414</td> <td>92</td> <td>20</td> <td>NaN</td> <td>65</td> <td>14</td> <td>68</td> <td>101</td> <td>59</td> <td>692.01</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr>

			<tr> <td>7.3211</td> <td>88</td> <td>3</td> <td>2.2282</td> <td>61</td> <td>96</td> <td>49</td> <td>101</td> <td>59</td> <td>NaN</td> <td>0</td> <td>19.099</td> <td>98</td> </tr>
			
		</table><br>

		<p> On observation, both train and test data sets contained randomly missing entries, and there seemed to be no pattern to the missing entries, i.e. data was missing completely at random. In addition, there were very few entires that contained no missing data. Only about 600 entries contained no missing information from 10,500, the total number of entries. As the data contained mixed features (continuous and categorical), there was no method reported in literature that could be used to estimate the missing entries using an approach such as a joint distribution of the features.</p>

		<p>It was thus decided to estimate each continuous features independent of each other. For continuous features, the technique of mean imputation was used, which replaces missing values with the mean of the distribution over the available features. A similar approach is followed for categorical features, but uses the mode (most commonly occuring category) of each categorical feature.</p>

    </div>
</body>